{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ИСТОЧНИКИ\n",
    "\n",
    "https://www.kaggle.com/tunguz/russian-glove/downloads/russian-glove.zip/1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import nltk\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_sentences(src = \"data/poems.txt\"):\n",
    "    file_path_src = src\n",
    "    allHaiku = []\n",
    "    with open(file_path_src, encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "        by3lines = []\n",
    "        for line in lines:\n",
    "            if line.strip() == \"\":\n",
    "                allHaiku.append(by3lines)\n",
    "                by3lines = []\n",
    "            else:\n",
    "                by3lines.append(line.lower())\n",
    "    return allHaiku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_oneline(data):\n",
    "    return [\"\".join(row) for row in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentences(file):\n",
    "    return to_oneline(stream_sentences(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = get_sentences(\"data/poems_fix.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download glove file from Kaggle to data directory\n",
    "\n",
    "https://www.kaggle.com/tunguz/russian-glove\n",
    "\n",
    "TODO: request file from shareable URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove_vectors(glove_file, embed_size=300):\n",
    "    words = [\n",
    "        \"PAD\",\n",
    "        \"UNK\"]\n",
    "    vects = [\n",
    "        np.zeros((embed_size)), # PAD\n",
    "        np.random.uniform(-1, 1, embed_size)] # UNK\n",
    "\n",
    "    fglove = open(glove_file, \"rb\")\n",
    "    for line in fglove:\n",
    "        cols = line.strip().split()\n",
    "        word = cols[0].decode('utf-8')\n",
    "        vect = np.array([float(v) for v in cols[1:]])\n",
    "        words.append(word)\n",
    "        vects.append(vect)\n",
    "\n",
    "    vocab = {w: i for i, w in enumerate(words)}\n",
    "    return words, vocab, np.array(vects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "words, vocab, embeddings = load_glove_vectors(\"data/multilingual_embeddings.ru\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63068, 300)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "glove2word2vec(glove_input_file=\"data/multilingual_embeddings.ru\", word2vec_output_file=\"data/gensim_glove_vectors.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "glove_model = KeyedVectors.load_word2vec_format(\"data/gensim_glove_vectors.txt\", binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('оборачиваетесь', 0.7298823595046997),\n",
       " ('а', 0.7228611707687378),\n",
       " ('черно', 0.654677152633667),\n",
       " ('обеспеченные', 0.6393757462501526),\n",
       " ('поднимаются', 0.6386812925338745),\n",
       " ('мерцающее', 0.6307729482650757),\n",
       " ('разбираем', 0.6296200752258301),\n",
       " ('маршировать', 0.6277832984924316),\n",
       " ('поступая', 0.6192404627799988),\n",
       " ('повторяли', 0.6133629679679871)]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_model.most_similar(\"и\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'оборачиваетесь'"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_model.similar_by_vector(embeddings[vocab[\"и\"]])[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63070, 300)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13027"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[\"и\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'и'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[13027]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_word2id(word, vocab):\n",
    "    return vocab[\"UNK\"] if vocab.get(word) == None else vocab[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "\n",
    "SEQUENCE_LEN = 20\n",
    "\n",
    "except_words = collections.Counter()\n",
    "normal_words = {}\n",
    "tokens_vectors = [[w for w in nltk.word_tokenize(s)] for s in sents]\n",
    "# verse_index_vectors = [[safe_word2id(w, vocab) for w in s] for s in tokens_vectors]\n",
    "windex_vectors = []\n",
    "good_sentences = []\n",
    "good_verses = []\n",
    "for s in tokens_vectors:\n",
    "    sent_vect = []\n",
    "    unk_count = 0\n",
    "    for w in s:\n",
    "        i = safe_word2id(w, vocab)\n",
    "        sent_vect.append(i)\n",
    "        if (i == vocab[\"UNK\"]):\n",
    "            unk_count += 1\n",
    "            except_words[w] += 1\n",
    "        else:\n",
    "            normal_words[w] = 1\n",
    "\n",
    "    windex_vectors.append(sent_vect)\n",
    "    if unk_count < 2 and s != []:\n",
    "        good_sentences.append(sent_vect)\n",
    "        good_verses.append(s)\n",
    "\n",
    "# [[safe_word2id(w, vocab) for w in s] for s in tokens_vectors]\n",
    "verse_index_vectors = sequence.pad_sequences(windex_vectors, SEQUENCE_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1789"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(good_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"data/good.txt\", sequence.pad_sequences(good_sentences, SEQUENCE_LEN), delimiter=\"\\t\")\n",
    "# r = np.genfromtxt(\"data/index.txt\", delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14092"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(normal_words.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16676"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(except_words.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_common_exceptions(sents, n = 40):\n",
    "    except_words = collections.Counter()\n",
    "    normal_words = {}\n",
    "    tokens_vectors = [[w for w in nltk.word_tokenize(s)] for s in sents]\n",
    "    # verse_index_vectors = [[safe_word2id(w, vocab) for w in s] for s in tokens_vectors]\n",
    "    windex_vectors = []\n",
    "    for s in tokens_vectors:\n",
    "        sent_vect = []\n",
    "        for w in s:\n",
    "            i = safe_word2id(w, vocab)\n",
    "            sent_vect.append(i)\n",
    "            if (i == vocab[\"UNK\"]):\n",
    "                except_words[w] += 1\n",
    "            else:\n",
    "                normal_words[w] = 1\n",
    "\n",
    "        windex_vectors.append(sent_vect)\n",
    "\n",
    "    return except_words.most_common(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens2index(tokens_vectors, seq_len = SEQUENCE_LEN):\n",
    "    windex_vectors = [[safe_word2id(w, vocab) for w in s] for s in tokens_vectors]\n",
    "    sequence.pad_sequences(windex_vectors, seq_len)\n",
    "\n",
    "def index2vectors(index_vectors):\n",
    "    return embeddings[index_vectors]\n",
    "\n",
    "def vectors2tokens(vectors):\n",
    "    for sent in vectors:\n",
    "        print(\" \".join([glove_model.similar_by_vector(word_vect)[0][0] for word_vect in sent]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replacex2y(x, y):\n",
    "    file_path = 'data/poems_fix.txt'\n",
    "    s = \"\"\n",
    "    with open(file_path, 'r') as myfile:\n",
    "      s = myfile.read()\n",
    "    s = s.replace(x, y)\n",
    "    with open(file_path, 'w') as myfile:\n",
    "      myfile.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "def a2b(b, a):\n",
    "    for n in a:\n",
    "        replacex2y(\" \" + n + \" \", \" \" + b + \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacex2y(\"\\n\", \" \\n \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacex2y(\" што \", \" что \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacex2y(\" говна \", \" дерьма \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacex2y(\" говно \", \" дерьмо \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacex2y(\" хуй \", \" хер \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacex2y(\" исус \", \" иисус \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacex2y(\" исуса \", \" иисуса \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacex2y(\" глядит \", \" смотрит \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacex2y(\" тихонько \", \" тихо \")\n",
    "replacex2y(\" тихонечко \", \" тихо \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacex2y(\" чаю \", \" чая \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacex2y(\" жопа \", \" опа \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacex2y(\" жопы \", \" мат \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacex2y(\" жопе \", \" мат \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacex2y(\" сука \", \" мат \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacex2y(\" жопу \", \" мат \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacex2y(\" жопой \", \" мат \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacex2y(\" минет \", \" мат \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacex2y(\" молчит \", \" молчат \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacex2y(\" пиздец \", \" конец \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacex2y(\" глядят \", \" смотрят \")\n",
    "replacex2y(\" гляжу \", \" смотрю \")\n",
    "replacex2y(\" глядишь \", \" глядишь \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacex2y(\" ево \", \" его \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacex2y(\" чтото \", \" что то \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacex2y(\" гдето \", \" где то \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacex2y(\" ктото \", \" кто то \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacex2y(\" изза \", \" из за \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacex2y(\" както \", \" как то \")\n",
    "replacex2y(\" чтонибудь \", \" что нибудь \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacex2y(\" наутро \", \" на утро \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacex2y(\" иль \", \" или \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacex2y(\" щас \", \" сейчас \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacex2y(\" ещо \", \" еще \")\n",
    "replacex2y(\" умрем \", \" умрём \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacex2y(\" вобще \", \" вообще \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacex2y(\" покуда \", \" пока \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacex2y(\" чорных \", \" чёрных \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacex2y(\" чорный \", \" чёрный \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacex2y(\" чорные \", \" чёрные \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacex2y(\" чорное \", \" чёрное \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacex2y(\" страшней \", \" страшнее \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacex2y(\" рукою \", \" рукой \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacex2y(\" весною \", \" весной \")\n",
    "replacex2y(\" порою \", \" порой \")\n",
    "replacex2y(\" зовёт \", \" зовет \")\n",
    "replacex2y(\" толпою \", \" толпой \")\n",
    "replacex2y(\" своею \", \" своей \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2b(\"нечаянно\", [\"невзначай\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\n",
    " 'олег',\n",
    " 'оксана',\n",
    " 'аркадий',\n",
    " 'глеб',\n",
    " 'олега',\n",
    " 'николая',\n",
    " 'геннадий',\n",
    " 'евгений',\n",
    " 'семён',\n",
    " 'петра',\n",
    " 'зухра',\n",
    " 'оксану',\n",
    " 'илья',\n",
    " 'глеба',\n",
    " 'олегу',\n",
    " 'оксане',\n",
    " 'иван',\n",
    " 'семен',\n",
    " 'ольга',\n",
    " 'анатолий',\n",
    " 'зульфия',\n",
    " 'оксаны',\n",
    " 'пётр',\n",
    " 'зоя',\n",
    " 'руфь',\n",
    " 'вениамин',\n",
    " 'антон',\n",
    " 'путин',\n",
    " 'петру',\n",
    " 'шаинский',\n",
    " 'игорь',\n",
    " 'андрей',\n",
    " 'семёна',\n",
    " 'пушкин',\n",
    " 'гагарин',\n",
    " 'павел',\n",
    " 'зухры',\n",
    " 'илье',\n",
    " 'оксаной',\n",
    " 'ильич',\n",
    " 'константин',\n",
    " 'иннокентий',\n",
    " 'николаем',\n",
    " 'зинаида',\n",
    " 'зульфии',\n",
    " 'зухре',\n",
    " 'ольги',\n",
    " 'николаю',\n",
    " 'олегом',\n",
    " 'зои',\n",
    " 'петрович',\n",
    " 'аделаида',\n",
    " 'марина',\n",
    " 'афанасий',\n",
    " 'глебу',\n",
    " 'зульфию',\n",
    " 'лариса',\n",
    " 'василий',\n",
    " 'петр',\n",
    " 'муму',\n",
    " 'татьяна',\n",
    " 'зое',\n",
    " 'ольгу',\n",
    " 'ильи',\n",
    " 'серёжа',\n",
    " 'маша',\n",
    " 'юра',\n",
    " 'друзь',\n",
    " 'михаил',\n",
    " 'герасим',\n",
    " 'игоря',\n",
    " 'ленин',\n",
    " 'аркадию',\n",
    " 'илью',\n",
    " 'андрея',\n",
    " 'ильича',\n",
    " 'саша',\n",
    " 'эммануил',\n",
    " 'зухру',\n",
    " 'иуда',\n",
    " 'фёдор',\n",
    " 'боярский',\n",
    " 'олеге',\n",
    " 'петыр',\n",
    " 'алексей',\n",
    " 'ольгой',\n",
    " 'кобзон',\n",
    " 'коля',\n",
    " 'оксан',\n",
    " 'ивана',\n",
    "]\n",
    "\n",
    "for n in names:\n",
    "    replacex2y(\" \" + n + \" \", \" имя \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\n",
    " 'борщ',\n",
    " 'пельмени',\n",
    " 'водку',\n",
    " 'пирожки',\n",
    " 'пирожок',\n",
    " 'пельменей',\n",
    " 'омлет',\n",
    " 'кастрюлю',\n",
    " 'борща',\n",
    " 'солью',\n",
    " 'колбасы',\n",
    " 'арбузы',\n",
    " 'пельменя',\n",
    " 'пельмень',\n",
    " 'котлеты',\n",
    "]\n",
    "\n",
    "for n in names:\n",
    "    replacex2y(\" \" + n + \" \", \" еда \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2b(\"умер\", [\n",
    "    \"помер\",\n",
    "    \"сдох\",\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2b(\"мат\", [\n",
    "    \"срать\",\n",
    "    \"мудак\",\n",
    "    \"блядь\",\n",
    "    \"блять\",\n",
    "    \"попу\",\n",
    "    \"говном\",\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2b(\"коробка\", [\"гроб\"])\n",
    "a2b(\"коробки\", [\"гроба\", \"гробы\"])\n",
    "a2b(\"могилы\", [\"могил\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['седой',\n",
       " 'седая',\n",
       " 'рублей',\n",
       " 'жених',\n",
       " 'косой',\n",
       " 'семнадцать',\n",
       " 'ночами',\n",
       " 'подъезда',\n",
       " 'крикнул',\n",
       " 'лужи',\n",
       " 'москву',\n",
       " 'горько',\n",
       " 'приснился',\n",
       " 'сантехник',\n",
       " 'снится',\n",
       " 'пятьсот',\n",
       " 'трамвае',\n",
       " 'ежа',\n",
       " 'усталый',\n",
       " 'гладит',\n",
       " 'вибратор',\n",
       " 'зонт',\n",
       " 'воет',\n",
       " 'подъезде',\n",
       " 'трамвай',\n",
       " 'тапки',\n",
       " 'молчу',\n",
       " 'курю',\n",
       " 'украдкой',\n",
       " 'попробуй',\n",
       " 'запел',\n",
       " 'плюнул',\n",
       " 'шорох',\n",
       " 'трусах',\n",
       " 'москва',\n",
       " 'горлу',\n",
       " 'девчонка',\n",
       " 'палач',\n",
       " 'шагает',\n",
       " 'крым',\n",
       " 'срывает',\n",
       " 'целовал',\n",
       " 'мордой',\n",
       " 'трогают',\n",
       " 'кончилась',\n",
       " 'енота',\n",
       " 'лежим',\n",
       " 'бомж',\n",
       " 'раскинув',\n",
       " 'убей',\n",
       " 'уставший',\n",
       " 'трамвая',\n",
       " 'уснул',\n",
       " 'воскрес',\n",
       " 'журавлей',\n",
       " 'старенький',\n",
       " 'гуляет',\n",
       " 'колготки',\n",
       " 'бредёт',\n",
       " 'лежишь',\n",
       " 'промолвил',\n",
       " 'четырнадцать',\n",
       " 'поцеловал',\n",
       " 'ползи',\n",
       " 'дорешал',\n",
       " 'стучится',\n",
       " 'утру',\n",
       " 'трахаться',\n",
       " 'плаще',\n",
       " 'ёж',\n",
       " 'портфель',\n",
       " 'бухло',\n",
       " 'пляшут',\n",
       " 'крематорий',\n",
       " 'обнявшись',\n",
       " 'трусов',\n",
       " 'буратино',\n",
       " 'тёплый',\n",
       " 'цыганка',\n",
       " 'дедмороза',\n",
       " 'весенний',\n",
       " 'гладить',\n",
       " 'ждёшь',\n",
       " 'глядишь',\n",
       " 'буркнул',\n",
       " 'село',\n",
       " 'речке',\n",
       " 'слепил',\n",
       " 'кладет',\n",
       " 'оделся',\n",
       " 'прохожим',\n",
       " 'тугие',\n",
       " 'луже',\n",
       " 'сунул',\n",
       " 'патроны',\n",
       " 'прораб',\n",
       " 'вздохнул',\n",
       " 'ладоней',\n",
       " 'зонтом',\n",
       " 'шторы',\n",
       " 'краснея',\n",
       " 'молчали',\n",
       " 'мокрый',\n",
       " 'насовсем',\n",
       " 'август',\n",
       " 'ползет',\n",
       " 'повесился',\n",
       " 'слюной',\n",
       " 'курил',\n",
       " 'сову',\n",
       " 'осенний',\n",
       " 'бэ',\n",
       " 'тум',\n",
       " 'невесту',\n",
       " 'свадебный',\n",
       " 'молчал',\n",
       " 'ветвях',\n",
       " 'вяло',\n",
       " 'заборе',\n",
       " 'тычет',\n",
       " 'кузьмича',\n",
       " 'валялся',\n",
       " 'тёмный',\n",
       " 'поспать',\n",
       " 'орал',\n",
       " 'тошнит',\n",
       " 'пал',\n",
       " 'закрыв',\n",
       " 'привычке',\n",
       " 'хомяк',\n",
       " 'бабка',\n",
       " 'трёт',\n",
       " 'вечерний',\n",
       " 'петербург',\n",
       " 'мужиков',\n",
       " 'хрустальный',\n",
       " 'тревогой',\n",
       " 'ложкой',\n",
       " 'ведром',\n",
       " 'дрожат',\n",
       " 'выпью',\n",
       " 'угрюмый',\n",
       " 'твердил',\n",
       " 'дачу',\n",
       " 'клоун',\n",
       " 'огонёк',\n",
       " 'раздеваться',\n",
       " 'бойцы',\n",
       " 'углам',\n",
       " 'шестнадцать']"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(lambda x: x[0], get_common_exceptions(get_sentences(\"data/poems_fix.txt\"), 150)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50816"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[\"ну\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "\n",
    "SEQUENCE_LEN = 20\n",
    "\n",
    "except_words = collections.Counter()\n",
    "normal_words = {}\n",
    "tokens_vectors = [[w for w in nltk.word_tokenize(s)] for s in sents]\n",
    "# verse_index_vectors = [[safe_word2id(w, vocab) for w in s] for s in tokens_vectors]\n",
    "windex_vectors = []\n",
    "good_sentences = []\n",
    "good_verses = []\n",
    "for s in tokens_vectors:\n",
    "    sent_vect = []\n",
    "    unk_count = 0\n",
    "    for w in s:\n",
    "        i = safe_word2id(w, vocab)\n",
    "        sent_vect.append(i)\n",
    "        if (i == vocab[\"UNK\"]):\n",
    "            unk_count += 1\n",
    "            except_words[w] += 1\n",
    "        else:\n",
    "            normal_words[w] = 1\n",
    "\n",
    "    windex_vectors.append(sent_vect)\n",
    "    if unk_count < 2 and s != []:\n",
    "        good_sentences.append(sent_vect)\n",
    "        good_verses.append(s)\n",
    "\n",
    "# [[safe_word2id(w, vocab) for w in s] for s in tokens_vectors]\n",
    "verse_index_vectors = sequence.pad_sequences(windex_vectors, SEQUENCE_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(good_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"data/good.txt\", sequence.pad_sequences(good_sentences, SEQUENCE_LEN), delimiter=\"\\t\")\n",
    "# r = np.genfromtxt(\"data/index.txt\", delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
