{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Автокодировщики - это класс нейронных сетей, которые пытаются реконструировать входные данные с применением обратного распространения. Автокодировщик состоит из двух частей: кодировщик и декодер. Кодировщик читает входные данные и сжимает их, порождая более компактное представление, а декодер читает это представление и пытается восстановить по нему вход. Иными словами, автокодировщик пытается обучить тождественную функцию, минимизируя ошибку реконструкции.\n",
    "На первый взгляд, тождественная функция не представляет ничего интересного, но важно, как именно производится обучение. Число скрытых слоев автокодировщика обычно меньше числа входных (и выходных) блоков. Это вынуждает кодировщик обучаться сжатому представлению входа, которое декодер реконструирует. Если входные данные обладают структурой в виде корреляций между входными признаками, то автокодировщик выявит некоторые корреляции и в итоге обучится представлению данных меньшей размерности аналогично тому, как это делается в методе главных компонент (principal component analysis, РСА)\n",
    "\n",
    "Обучив автокодировщик, декодер обычно отбрасывают и используют только кодировщик для порождения компактных представлений входных данных. Можно вместо этого использовать кодировщик как детектор признаков, порождающий компактное, семантически полноценное представление входа, и построить классификатор, присоединив к скрытому слою слой с функцией активации softmax.\n",
    "\n",
    "Ранее мы уже встречались с погружениями слов, в результате чего получается вектор, представляющий смысл слова в контексте других слов, совместно с которыми оно встречается. А сейчас мы посмотрим, как построить аналогичные векторы для предложений. Предложение - это последовательность слов, а вектор предложения представляет его смысл.\n",
    "Самый простой способ построить вектор предложения - сложить все векторы слов и поделить сумму на число слов. Но в этом случае предложение трактуется как мешок слов, и порядок слов не принимается во внимание. При таком подходе предложения The dog bit the man (Собака укусила человека) и The man bit the dog (Человек укусил собаку) считались бы идентичными. LSTM предназначена для работы с входными последовательностями и учитывает порядок слов, поэтому является более естественным представлением предложения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ИСТОЧНИКИ\n",
    "\n",
    "https://www.kaggle.com/tunguz/russian-glove/downloads/russian-glove.zip/1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import nltk\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_sentences(src = \"data/poems.txt\"):\n",
    "    file_path_src = src\n",
    "    allHaiku = []\n",
    "    with open(file_path_src, encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "        by3lines = []\n",
    "        for line in lines:\n",
    "            if line == \"\\n\":\n",
    "                allHaiku.append(by3lines)\n",
    "                by3lines = []\n",
    "            else:\n",
    "                by3lines.append(line.lower())\n",
    "    return allHaiku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_oneline(data):\n",
    "    return [\"\".join(row) for row in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = to_oneline(stream_sentences())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download glove file from Kaggle to data directory\n",
    "\n",
    "https://www.kaggle.com/tunguz/russian-glove\n",
    "\n",
    "TODO: request file from shareable URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove_vectors(glove_file, embed_size=300):\n",
    "    words = [\n",
    "        \"PAD\",\n",
    "        \"UNK\"]\n",
    "    vects = [\n",
    "        np.zeros((embed_size)), # PAD\n",
    "        np.random.uniform(-1, 1, embed_size)] # UNK\n",
    "\n",
    "    fglove = open(glove_file, \"rb\")\n",
    "    for line in fglove:\n",
    "        cols = line.strip().split()\n",
    "        word = cols[0].decode('utf-8')\n",
    "        vect = np.array([float(v) for v in cols[1:]])\n",
    "        words.append(word)\n",
    "        vects.append(vect)\n",
    "\n",
    "    vocab = {w: i for i, w in enumerate(words)}\n",
    "    return words, vocab, np.array(vects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "words, vocab, embeddings = load_glove_vectors(\"data/multilingual_embeddings.ru\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63070, 300)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13027"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[\"и\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'и'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[13027]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_word2id(word, vocab):\n",
    "    return vocab[\"UNK\"] if vocab.get(word) == None else vocab[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "\n",
    "SEQUENCE_LEN = 20\n",
    "\n",
    "verse_index_vectors = [[safe_word2id(w, vocab) for w in nltk.word_tokenize(s)] for s in sents]\n",
    "verse_index_vectors = sequence.pad_sequences(verse_index_vectors, SEQUENCE_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7509, 20)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verse_index_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"data/index.txt\", verse_index_vectors, delimiter=\"\\t\")\n",
    "# r = np.genfromtxt(\"data/index.txt\", delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель автокодировщика принимает последовательность GloVe-векторов слов и обучается порождать другую последовательность, похожую на входную. LSTM-кодировщик сжимает последовательность в контекстный вектор фиксированной длины, по которой LSTM-декодер реконструирует исходную последовательность."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import division, print_function\n",
    "from __future__ import absolute_import\n",
    "from __future__ import unicode_literals\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import RepeatVector\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import sequence\n",
    "import collections\n",
    "import nltk\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from time import gmtime, strftime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# msin\n",
    "def compute_cosine_similarity(x, y):\n",
    "    return np.dot(x, y) / (np.linalg.norm(x, 2) * np.linalg.norm(y, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of sentences:  7509\n",
      "(5256, 20) (2253, 20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# split sentences into training and test\n",
    "train_size = 0.7\n",
    "Xtrain, Xtest = train_test_split(verse_index_vectors, train_size=train_size)\n",
    "print(\"number of sentences: \", len(verse_index_vectors))\n",
    "print(Xtrain.shape, Xtest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generator(X, embeddings, batch_size):\n",
    "    while True:\n",
    "        # loop once per epoch\n",
    "        num_recs = X.shape[0]\n",
    "        indices = np.random.permutation(np.arange(num_recs))\n",
    "        num_batches = num_recs // batch_size\n",
    "        for bid in range(num_batches):\n",
    "            sids = indices[bid * batch_size: (bid + 1) * batch_size]\n",
    "            Xbatch = embeddings[X[sids, :]]\n",
    "            yield Xbatch, Xbatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63070, 300)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5256, 20)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2253, 20)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training and test generators\n",
    "BATCH_SIZE = 64\n",
    "train_gen = sentence_generator(Xtrain, embeddings, BATCH_SIZE)\n",
    "test_gen = sentence_generator(Xtest, embeddings, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import absolute_import\n",
    "from __future__ import unicode_literals\n",
    "from time import gmtime, strftime\n",
    "from keras.callbacks import TensorBoard\n",
    "import os\n",
    "\n",
    "\n",
    "def make_tensorboard(set_dir_name=''):\n",
    "    tictoc = strftime(\"%a_%d_%b_%Y_%H_%M_%S\", gmtime())\n",
    "    directory_name = tictoc\n",
    "    log_dir = set_dir_name + '_' + directory_name\n",
    "    os.mkdir(log_dir)\n",
    "    tensorboard = TensorBoard(log_dir=log_dir, write_graph=True, )\n",
    "    return tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n"
     ]
    }
   ],
   "source": [
    "# define autoencoder network\n",
    "EMBED_SIZE = 300\n",
    "LATENT_SIZE = 512\n",
    "\n",
    "inputs = Input(shape=(SEQUENCE_LEN, EMBED_SIZE), name=\"input\")\n",
    "encoded = Bidirectional(LSTM(LATENT_SIZE), merge_mode=\"sum\",\n",
    "                        name=\"encoder_lstm\")(inputs)\n",
    "\n",
    "decoded = RepeatVector(SEQUENCE_LEN, name=\"repeater\")(encoded)\n",
    "decoded = Bidirectional(LSTM(EMBED_SIZE, return_sequences=True),\n",
    "                        merge_mode=\"sum\",\n",
    "                        name=\"decoder_lstm\")(decoded)\n",
    "\n",
    "autoencoder = Model(inputs, decoded)\n",
    "\n",
    "tensorboard = make_tensorboard(set_dir_name='rnn')\n",
    "\n",
    "autoencoder.compile(optimizer=\"sgd\", loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "82/82 [==============================] - 48s 581ms/step - loss: 0.1947 - val_loss: 0.1948\n",
      "Epoch 2/10\n",
      "82/82 [==============================] - 47s 570ms/step - loss: 0.1914 - val_loss: 0.1918\n",
      "Epoch 3/10\n",
      "82/82 [==============================] - 46s 561ms/step - loss: 0.1887 - val_loss: 0.1894\n",
      "Epoch 4/10\n",
      "82/82 [==============================] - 45s 554ms/step - loss: 0.1865 - val_loss: 0.1872\n",
      "Epoch 5/10\n",
      "82/82 [==============================] - 46s 557ms/step - loss: 0.1846 - val_loss: 0.1853\n",
      "Epoch 6/10\n",
      "82/82 [==============================] - 46s 556ms/step - loss: 0.1830 - val_loss: 0.1839\n",
      "Epoch 7/10\n",
      "82/82 [==============================] - 46s 559ms/step - loss: 0.1816 - val_loss: 0.1827\n",
      "Epoch 8/10\n",
      "82/82 [==============================] - 46s 557ms/step - loss: 0.1803 - val_loss: 0.1812\n",
      "Epoch 9/10\n",
      "82/82 [==============================] - 46s 556ms/step - loss: 0.1792 - val_loss: 0.1803\n",
      "Epoch 10/10\n",
      "82/82 [==============================] - 46s 555ms/step - loss: 0.1782 - val_loss: 0.1792\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "NUM_EPOCHS = 10\n",
    "DATA_DIR = \"data\"\n",
    "\n",
    "num_train_steps = len(Xtrain) // BATCH_SIZE\n",
    "num_test_steps = len(Xtest) // BATCH_SIZE\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath=os.path.join(DATA_DIR, \"sent-thoughts-autoencoder.h5\"),\n",
    "    save_best_only=True)\n",
    "\n",
    "history = autoencoder.fit_generator(train_gen,\n",
    "                                    steps_per_epoch=num_train_steps,\n",
    "                                    epochs=NUM_EPOCHS,\n",
    "                                    validation_data=test_gen,\n",
    "                                    validation_steps=num_test_steps,\n",
    "                                    callbacks=[checkpoint, tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract encoder model\n",
    "encoder = Model(autoencoder.input, autoencoder.get_layer(\"encoder_lstm\").output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4585866630077362\n",
      "0.53293377161026\n",
      "0.34642577171325684\n",
      "0.5201818943023682\n",
      "0.3025127053260803\n",
      "0.3962501883506775\n",
      "0.3903942406177521\n",
      "0.37477990984916687\n",
      "0.1981249302625656\n",
      "0.5313827991485596\n",
      "0.3183656334877014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_axes.py:6521: MatplotlibDeprecationWarning: \n",
      "The 'normed' kwarg was deprecated in Matplotlib 2.1 and will be removed in 3.1. Use 'density' instead.\n",
      "  alternative=\"'density'\", removal=\"3.1\")\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# collect autoencoder predictions for test set\n",
    "test_inputs, test_labels = next(test_gen)\n",
    "preds = autoencoder.predict(test_inputs)\n",
    "\n",
    "# compute difference between vector produced by original and autoencoded\n",
    "k = 500\n",
    "cosims = np.zeros((k))\n",
    "i = 0\n",
    "for bid in range(num_test_steps):\n",
    "    xtest, ytest = next(test_gen)\n",
    "    ytest_ = autoencoder.predict(xtest)\n",
    "    Xvec = encoder.predict(xtest)\n",
    "    Yvec = encoder.predict(ytest_)\n",
    "    for rid in range(Xvec.shape[0]):\n",
    "        if i >= k:\n",
    "            break\n",
    "        cosims[i] = compute_cosine_similarity(Xvec[rid], Yvec[rid])\n",
    "        if i <= 10:\n",
    "            print(cosims[i])\n",
    "        i += 1\n",
    "    if i >= k:\n",
    "        break\n",
    "\n",
    "plt.hist(cosims, bins=10, normed=True)\n",
    "plt.xlabel(\"cosine similarity\")\n",
    "plt.ylabel(\"frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
