{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Идея этого этапа работы в использовании autoencoder совместно с GAN.\n",
    "\n",
    "Мой план предобучить autoencoder на хороших пирожках (без матов и непонятных слов их оказывается около 1789) чтобы он научился вычленять и восстанавливать смысл стиха.\n",
    "\n",
    "Далее построить GAN с такими генератором и дискриминатором:\n",
    "\n",
    "**generator**: (noise -> dense(latent size) -> decoder(trainable = False)) = sample пирожок\n",
    "\n",
    "**discriminator**: (verse -> encoder(trainable = False) -> dense(1)) = пирожок / не пирожок\n",
    "\n",
    "Ход работы ниже..\n",
    "\n",
    "Теперь к проблемам :(\n",
    "\n",
    "Запланированную архитектуру в коде мне удалось построить, однако результат оказался плохим.\n",
    "\n",
    "Я начал дебажить и понял, что мой autoencoder очень плохо восстанавливает предложение по входному образцу. Много повторений и бессмысленных слов. Я прогнал его на большом числе эпох, но он застревает на loss=0.15 и крутится возле этой отметки, не улучшаясь. Можно увидеть ниже.\n",
    "\n",
    "**Роман Николаевич**, посоветуйте, пожалуйста, что можно сделать?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import nltk\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для работы понадобится скачать в папку data предобученный glove файл для русского языка\n",
    "\n",
    "https://www.kaggle.com/tunguz/russian-glove/downloads/russian-glove.zip/1\n",
    "\n",
    "используем команды ниже"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -L https://www.dropbox.com/s/px2srte22xbq2pu/multilingual_embeddings.ru?dl=0 > data/multilingual_embeddings.ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove_vectors(glove_file, embed_size=300):\n",
    "    words = [\n",
    "        \"PAD\",\n",
    "        \"UNK\"]\n",
    "    vects = [\n",
    "        np.zeros((embed_size)), # PAD\n",
    "        np.random.uniform(-1, 1, embed_size)] # UNK\n",
    "\n",
    "    fglove = open(glove_file, \"rb\")\n",
    "    for line in fglove:\n",
    "        cols = line.strip().split()\n",
    "        word = cols[0].decode('utf-8')\n",
    "        vect = np.array([float(v) for v in cols[1:]])\n",
    "        words.append(word)\n",
    "        vects.append(vect)\n",
    "\n",
    "    vocab = {w: i for i, w in enumerate(words)}\n",
    "    return words, vocab, np.array(vects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "words, vocab, embeddings = load_glove_vectors(\"data/multilingual_embeddings.ru\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63068, 300)"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "glove2word2vec(glove_input_file=\"data/multilingual_embeddings.ru\", word2vec_output_file=\"data/gensim_glove_vectors.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "glove_model = KeyedVectors.load_word2vec_format(\"data/gensim_glove_vectors.txt\", binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('оборачиваетесь', 0.7298823595046997),\n",
       " ('а', 0.7228611707687378),\n",
       " ('черно', 0.654677152633667),\n",
       " ('обеспеченные', 0.6393757462501526),\n",
       " ('поднимаются', 0.6386812925338745),\n",
       " ('мерцающее', 0.6307729482650757),\n",
       " ('разбираем', 0.6296200752258301),\n",
       " ('маршировать', 0.6277832984924316),\n",
       " ('поступая', 0.6192404627799988),\n",
       " ('повторяли', 0.6133629679679871)]"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_model.most_similar(\"и\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'и'"
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_model.similar_by_vector(embeddings[vocab[\"и\"]])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63070, 300)"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13027"
      ]
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[\"и\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'и'"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[13027]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_word2id(word, vocab):\n",
    "    return vocab[\"UNK\"] if vocab.get(word) == None else vocab[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_sentences = np.genfromtxt(\"data/good.txt\", delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens2index(tokens_vectors, seq_len = SEQUENCE_LEN):\n",
    "    windex_vectors = [[safe_word2id(w, vocab) for w in s] for s in tokens_vectors]\n",
    "    sequence.pad_sequences(windex_vectors, seq_len)\n",
    "\n",
    "def index2vectors(index_vectors):\n",
    "    return embeddings[index_vectors.astype(int)]\n",
    "\n",
    "def vectors2tokens(vectors):\n",
    "    for sent in vectors:\n",
    "        print(\" \".join([\n",
    "            glove_model.similar_by_vector(word_vect)[0][0] if sum(word_vect) != 0 else \"\" for word_vect in sent]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "нет в шоколаде шоколада давно нет мяса в пластики становится чуть чуть тревожно а вдруг и в людях нет людей\n",
      " я ненавижу вас так долго что в принципе уже забыл и почему вас ненавижу и кто вы собственно такой\n",
      "     подумай атомы вселенной пластики в состав тебя могли на что нибудь другое намного лучшее пойти\n"
     ]
    }
   ],
   "source": [
    "vectors2tokens(index2vectors(good_sentences[0:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель автокодировщика принимает последовательность GloVe-векторов слов и обучается порождать другую последовательность, похожую на входную. LSTM-кодировщик сжимает последовательность в контекстный вектор фиксированной длины, по которой LSTM-декодер реконструирует исходную последовательность."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import division, print_function\n",
    "from __future__ import absolute_import\n",
    "from __future__ import unicode_literals\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import RepeatVector\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import sequence\n",
    "import collections\n",
    "import nltk\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from time import gmtime, strftime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "# msin\n",
    "def compute_cosine_similarity(x, y):\n",
    "    return np.dot(x, y) / (np.linalg.norm(x, 2) * np.linalg.norm(y, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of sentences:  1789\n",
      "(1252, 20) (537, 20)\n"
     ]
    }
   ],
   "source": [
    "# split sentences into training and test\n",
    "train_size = 0.7\n",
    "Xtrain, Xtest = train_test_split(good_sentences, train_size=train_size)\n",
    "print(\"number of sentences: \", len(good_sentences))\n",
    "print(Xtrain.shape, Xtest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generator(X, embeddings, batch_size):\n",
    "    while True:\n",
    "        # loop once per epoch\n",
    "        num_recs = X.shape[0]\n",
    "        indices = np.random.permutation(np.arange(num_recs))\n",
    "        num_batches = num_recs // batch_size\n",
    "        for bid in range(num_batches):\n",
    "            sids = indices[bid * batch_size: (bid + 1) * batch_size]\n",
    "            Xbatch = index2vectors(X[sids, :])\n",
    "            yield Xbatch, Xbatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63070, 300)"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1252, 20)"
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(537, 20)"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training and test generators\n",
    "BATCH_SIZE = 64\n",
    "train_gen = sentence_generator(Xtrain, embeddings, BATCH_SIZE)\n",
    "test_gen = sentence_generator(Xtest, embeddings, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import absolute_import\n",
    "from __future__ import unicode_literals\n",
    "from time import gmtime, strftime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define autoencoder network\n",
    "EMBED_SIZE = 300\n",
    "LATENT_SIZE = 512\n",
    "\n",
    "inputs = Input(shape=(SEQUENCE_LEN, EMBED_SIZE), name=\"input\")\n",
    "encoded = Bidirectional(LSTM(LATENT_SIZE), merge_mode=\"sum\",\n",
    "                        name=\"encoder_lstm\")(inputs)\n",
    "\n",
    "decoded = RepeatVector(SEQUENCE_LEN, name=\"repeater\")(encoded)\n",
    "decoded = Bidirectional(LSTM(EMBED_SIZE, return_sequences=True),\n",
    "                        merge_mode=\"sum\",\n",
    "                        name=\"decoder_lstm\")(decoded)\n",
    "\n",
    "autoencoder = Model(inputs, decoded)\n",
    "\n",
    "autoencoder.compile(optimizer=\"sgd\", loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "19/19 [==============================] - 11s 595ms/step - loss: 0.1520 - val_loss: 0.1533\n",
      "Epoch 2/50\n",
      "19/19 [==============================] - 11s 587ms/step - loss: 0.1530 - val_loss: 0.1534\n",
      "Epoch 3/50\n",
      "19/19 [==============================] - 11s 581ms/step - loss: 0.1521 - val_loss: 0.1539\n",
      "Epoch 4/50\n",
      "19/19 [==============================] - 11s 588ms/step - loss: 0.1511 - val_loss: 0.1530\n",
      "Epoch 5/50\n",
      "19/19 [==============================] - 11s 599ms/step - loss: 0.1523 - val_loss: 0.1510\n",
      "Epoch 6/50\n",
      "19/19 [==============================] - 11s 586ms/step - loss: 0.1517 - val_loss: 0.1521\n",
      "Epoch 7/50\n",
      "19/19 [==============================] - 11s 586ms/step - loss: 0.1528 - val_loss: 0.1543\n",
      "Epoch 8/50\n",
      "19/19 [==============================] - 11s 586ms/step - loss: 0.1517 - val_loss: 0.1538\n",
      "Epoch 9/50\n",
      "19/19 [==============================] - 11s 587ms/step - loss: 0.1531 - val_loss: 0.1511\n",
      "Epoch 10/50\n",
      "19/19 [==============================] - 11s 601ms/step - loss: 0.1515 - val_loss: 0.1526\n",
      "Epoch 11/50\n",
      "19/19 [==============================] - 11s 586ms/step - loss: 0.1522 - val_loss: 0.1527\n",
      "Epoch 12/50\n",
      "19/19 [==============================] - 11s 586ms/step - loss: 0.1513 - val_loss: 0.1541\n",
      "Epoch 13/50\n",
      "19/19 [==============================] - 11s 597ms/step - loss: 0.1529 - val_loss: 0.1498\n",
      "Epoch 14/50\n",
      "19/19 [==============================] - 11s 585ms/step - loss: 0.1513 - val_loss: 0.1553\n",
      "Epoch 15/50\n",
      "19/19 [==============================] - 11s 565ms/step - loss: 0.1527 - val_loss: 0.1526\n",
      "Epoch 16/50\n",
      "19/19 [==============================] - 11s 588ms/step - loss: 0.1517 - val_loss: 0.1519\n",
      "Epoch 17/50\n",
      "19/19 [==============================] - 11s 587ms/step - loss: 0.1526 - val_loss: 0.1520\n",
      "Epoch 18/50\n",
      "19/19 [==============================] - 11s 586ms/step - loss: 0.1521 - val_loss: 0.1518\n",
      "Epoch 19/50\n",
      "19/19 [==============================] - 11s 603ms/step - loss: 0.1514 - val_loss: 0.1563\n",
      "Epoch 20/50\n",
      "19/19 [==============================] - 11s 586ms/step - loss: 0.1515 - val_loss: 0.1492\n",
      "Epoch 21/50\n",
      "19/19 [==============================] - 11s 585ms/step - loss: 0.1529 - val_loss: 0.1541\n",
      "Epoch 22/50\n",
      "19/19 [==============================] - 11s 589ms/step - loss: 0.1526 - val_loss: 0.1527\n",
      "Epoch 23/50\n",
      "19/19 [==============================] - 11s 585ms/step - loss: 0.1520 - val_loss: 0.1523\n",
      "Epoch 24/50\n",
      "19/19 [==============================] - 11s 585ms/step - loss: 0.1515 - val_loss: 0.1516\n",
      "Epoch 25/50\n",
      "19/19 [==============================] - 11s 584ms/step - loss: 0.1529 - val_loss: 0.1534\n",
      "Epoch 26/50\n",
      "19/19 [==============================] - 11s 591ms/step - loss: 0.1516 - val_loss: 0.1524\n",
      "Epoch 27/50\n",
      "19/19 [==============================] - 11s 588ms/step - loss: 0.1521 - val_loss: 0.1520\n",
      "Epoch 28/50\n",
      "19/19 [==============================] - 11s 602ms/step - loss: 0.1515 - val_loss: 0.1558\n",
      "Epoch 29/50\n",
      "19/19 [==============================] - 11s 601ms/step - loss: 0.1531 - val_loss: 0.1504\n",
      "Epoch 30/50\n",
      "19/19 [==============================] - 11s 586ms/step - loss: 0.1527 - val_loss: 0.1533\n",
      "Epoch 31/50\n",
      "19/19 [==============================] - 11s 588ms/step - loss: 0.1500 - val_loss: 0.1520\n",
      "Epoch 32/50\n",
      "19/19 [==============================] - 11s 584ms/step - loss: 0.1523 - val_loss: 0.1504\n",
      "Epoch 33/50\n",
      "19/19 [==============================] - 11s 596ms/step - loss: 0.1521 - val_loss: 0.1527\n",
      "Epoch 34/50\n",
      "19/19 [==============================] - 12s 625ms/step - loss: 0.1520 - val_loss: 0.1528\n",
      "Epoch 35/50\n",
      "19/19 [==============================] - 11s 585ms/step - loss: 0.1525 - val_loss: 0.1515\n",
      "Epoch 36/50\n",
      "19/19 [==============================] - 11s 585ms/step - loss: 0.1517 - val_loss: 0.1521\n",
      "Epoch 37/50\n",
      "19/19 [==============================] - 11s 593ms/step - loss: 0.1517 - val_loss: 0.1531\n",
      "Epoch 38/50\n",
      "19/19 [==============================] - 11s 586ms/step - loss: 0.1524 - val_loss: 0.1519\n",
      "Epoch 39/50\n",
      "19/19 [==============================] - 11s 586ms/step - loss: 0.1516 - val_loss: 0.1539\n",
      "Epoch 40/50\n",
      "19/19 [==============================] - 11s 588ms/step - loss: 0.1524 - val_loss: 0.1515\n",
      "Epoch 41/50\n",
      "19/19 [==============================] - 11s 590ms/step - loss: 0.1519 - val_loss: 0.1520\n",
      "Epoch 42/50\n",
      "19/19 [==============================] - 11s 596ms/step - loss: 0.1518 - val_loss: 0.1546\n",
      "Epoch 43/50\n",
      "19/19 [==============================] - 11s 590ms/step - loss: 0.1520 - val_loss: 0.1530\n",
      "Epoch 44/50\n",
      "19/19 [==============================] - 11s 591ms/step - loss: 0.1513 - val_loss: 0.1519\n",
      "Epoch 45/50\n",
      "19/19 [==============================] - 11s 590ms/step - loss: 0.1523 - val_loss: 0.1506\n",
      "Epoch 46/50\n",
      "19/19 [==============================] - 11s 592ms/step - loss: 0.1521 - val_loss: 0.1517\n",
      "Epoch 47/50\n",
      "19/19 [==============================] - 11s 584ms/step - loss: 0.1521 - val_loss: 0.1517\n",
      "Epoch 48/50\n",
      "19/19 [==============================] - 11s 593ms/step - loss: 0.1526 - val_loss: 0.1510\n",
      "Epoch 49/50\n",
      "19/19 [==============================] - 11s 598ms/step - loss: 0.1520 - val_loss: 0.1524\n",
      "Epoch 50/50\n",
      "19/19 [==============================] - 11s 590ms/step - loss: 0.1526 - val_loss: 0.1524\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "NUM_EPOCHS = 200\n",
    "DATA_DIR = \"data\"\n",
    "\n",
    "num_train_steps = len(Xtrain) // BATCH_SIZE\n",
    "num_test_steps = len(Xtest) // BATCH_SIZE\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath=os.path.join(DATA_DIR, \"sent-thoughts-autoencoder.h5\"),\n",
    "    save_best_only=True)\n",
    "\n",
    "history = autoencoder.fit_generator(train_gen,\n",
    "                                    steps_per_epoch=num_train_steps,\n",
    "                                    epochs=NUM_EPOCHS,\n",
    "                                    validation_data=test_gen,\n",
    "                                    validation_steps=num_test_steps,\n",
    "                                    callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract encoder model\n",
    "encoder = Model(autoencoder.input, autoencoder.get_layer(\"encoder_lstm\").output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 20, 300)           0         \n",
      "_________________________________________________________________\n",
      "encoder_lstm (Bidirectional) (None, 512)               3330048   \n",
      "_________________________________________________________________\n",
      "repeater (RepeatVector)      (None, 20, 512)           0         \n",
      "_________________________________________________________________\n",
      "decoder_lstm (Bidirectional) (None, 20, 300)           1951200   \n",
      "=================================================================\n",
      "Total params: 5,281,248\n",
      "Trainable params: 5,281,248\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_input = Input(shape=(LATENT_SIZE,))\n",
    "\n",
    "deco = autoencoder.get_layer(\"repeater\")(encoded_input)\n",
    "deco = autoencoder.get_layer(\"decoder_lstm\")(deco)\n",
    "\n",
    "# create the decoder model\n",
    "decoder = Model(encoded_input, deco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "repeater (RepeatVector)      (None, 20, 512)           0         \n",
      "_________________________________________________________________\n",
      "decoder_lstm (Bidirectional) (None, 20, 300)           1951200   \n",
      "=================================================================\n",
      "Total params: 1,951,200\n",
      "Trainable params: 1,951,200\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# collect autoencoder predictions for test set\n",
    "test_inputs, test_labels = next(test_gen)\n",
    "preds = autoencoder.predict(test_inputs)\n",
    "\n",
    "# compute difference between vector produced by original and autoencoded\n",
    "k = 500\n",
    "cosims = np.zeros((k))\n",
    "i = 0\n",
    "for bid in range(num_test_steps):\n",
    "    xtest, _ = next(test_gen)\n",
    "    ytest = autoencoder.predict(xtest)\n",
    "    Xvec = encoder.predict(xtest)\n",
    "    Yvec = encoder.predict(ytest)\n",
    "    for rid in range(Xvec.shape[0]):\n",
    "        if i >= k:\n",
    "            break\n",
    "        cosims[i] = compute_cosine_similarity(Xvec[rid], Yvec[rid])\n",
    "        i += 1\n",
    "    if i >= k:\n",
    "        break\n",
    "\n",
    "plt.hist(cosims, bins=10, normed=True)\n",
    "plt.xlabel(\"cosine similarity\")\n",
    "plt.ylabel(\"frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  на двадцать третье подарила я мужу чудные носки а он мне на пластики марта чудесный крем от синяков\n"
     ]
    }
   ],
   "source": [
    "vectors2tokens(index2vectors(good_sentences[10:11]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "вкратце вкратце вкратце вкратце вкратце вкратце вкратце ручкой ручкой ручкой ручкой ручкой ручкой ручкой ручкой ручкой ручкой ручкой ручкой ручкой\n",
      "маятника маятника маятника маятника маятника маятника маятника маятника маятника маятника маятника маятника маятника маятника маятника маятника настроить ручкой ручкой ручкой\n",
      "особо грустной грустной грустной грустной грустной грустной грустной грустной грустной грустной грустной грустной грустной грустной грустной грустной грустной грустной грустной\n",
      "вкратце вкратце вкратце вкратце вкратце настроить настроить настроить настроить настроить настроить настроить настроить настроить настроить настроить цельнозерновым цельнозерновым цельнозерновым цельнозерновым\n",
      "взгляда взгляда взгляда взгляда взгляда взгляда взгляда взгляда взгляда взгляда взгляда взгляда взгляда взгляда взгляда взгляда теста теста теста теста\n",
      "классическую классическую классическую классическую классическую классическую грустной грустной грустной грустной грустной грустной грустной грустной грустной грустной грустной грустной грустной грустной\n",
      "вкратце вкратце вкратце вкратце вкратце вкратце вкратце вкратце вкратце вкратце вкратце просмотреть просмотреть просмотреть просмотреть просмотреть грустной грустной грустной плюс\n",
      "подобрать подобрать подобрать подобрать подобрать подобрать добывать добывать добывать добывать добывать добывать добывать добывать добывать добывать добывать добывать добывать добывать\n",
      "показывается показывается грустной грустной грустной грустной грустной грустной грустной грустной грустной грустной грустной грустной грустной грустной грустной грустной грустной траффика\n",
      "готовы вкратце вкратце вкратце вкратце вкратце вкратце вкратце вкратце вкратце вкратце вкратце вкратце бизнесс бизнесс бизнесс бизнесс бизнесс бизнесс бизнесс\n"
     ]
    }
   ],
   "source": [
    "vectors2tokens(autoencoder.predict(index2vectors(good_sentences[20:30])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten\n",
    "from keras.layers import Activation\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator():\n",
    "    inputs = Input(shape=(100,))\n",
    "    latent = Dense(LATENT_SIZE, activation='sigmoid')(inputs)\n",
    "\n",
    "    decoder.trainable = False\n",
    "    decoded = decoder(latent)\n",
    "    \n",
    "    return Model(inputs, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator():\n",
    "    encoder.trainable = False\n",
    "    inputs = Input(shape=(SEQUENCE_LEN, EMBED_SIZE), name=\"input\")\n",
    "    encoded = encoder(inputs)\n",
    "    y = Dense(1, activation='sigmoid')(encoded)\n",
    "\n",
    "    return Model(inputs, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and compile the Discriminator\n",
    "discr = discriminator()\n",
    "discr.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "\n",
    "# Build the Generator\n",
    "gener = generator()\n",
    "\n",
    "# Generated image to be used as input\n",
    "noise = Input(shape=(100,))\n",
    "fakes = gener(noise)\n",
    "\n",
    "# Keep Discriminator’s parameters constant during Generator training\n",
    "# trainable = False should be set before compile\n",
    "discr.trainable = False\n",
    "\n",
    "# The Discriminator’s prediction\n",
    "prediction = discr(fakes)\n",
    "\n",
    "# Combined GAN model to train the Generator\n",
    "combined = Model(noise, prediction)\n",
    "combined.compile(loss='binary_crossentropy', optimizer=Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "accuracies = []\n",
    "\n",
    "def train(X_train, iterations, batch_size, sample_interval):\n",
    "    # Labels for real and fake examples\n",
    "    real = np.ones((batch_size, 1))\n",
    "    fake = np.zeros((batch_size, 1))\n",
    "\n",
    "    for iteration in range(iterations):\n",
    "        # -------------------------\n",
    "        #  Train the Discriminator\n",
    "        # -------------------------\n",
    "        idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "        real_imgs = X_train[idx] # Select a random batch of real images\n",
    "\n",
    "        z = np.random.normal(0, 1, (batch_size, 100))\n",
    "        fake_imgs = gener.predict(z) # Generate a batch of fake images\n",
    "\n",
    "        # Discriminator loss\n",
    "        d_loss_real = discr.train_on_batch(real_imgs, real)\n",
    "        d_loss_fake = discr.train_on_batch(fake_imgs, fake)\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train the Generator\n",
    "        # ---------------------\n",
    "\n",
    "        # Generate a batch of fake images\n",
    "        z = np.random.normal(0, 1, (batch_size, 100))\n",
    "\n",
    "        # Generator loss\n",
    "        g_loss = combined.train_on_batch(z, real)\n",
    "\n",
    "        if iteration % sample_interval == 0:\n",
    "            \n",
    "            # Output training progress\n",
    "            print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % \n",
    "                         (iteration, d_loss[0], 100*d_loss[1], g_loss))\n",
    "            \n",
    "            # Save losses and accuracies so they can be plotted after training\n",
    "            losses.append((d_loss[0], g_loss))\n",
    "            accuracies.append(100*d_loss[1])\n",
    "\n",
    "            # Output generated image samples \n",
    "            samples(iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [],
   "source": [
    "def samples(iteration):\n",
    "\n",
    "    # Sample random noise\n",
    "    z = np.random.normal(0, 1, (3, 100))\n",
    "\n",
    "    # Generate images from random noise\n",
    "    fakes = gener.predict(z)\n",
    "    \n",
    "    vectors2tokens(fakes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [D loss: 0.702067, acc.: 44.53%] [G loss: 0.651312]\n",
      "волосков волосков волосков волосков волосков волосков желтое пулеметная пулеметная пулеметная пулеметная пулеметная конструкторами конструкторами конструкторами конструкторами конструкторами конструкторами конструкторами конструкторами\n",
      "электроэнцефалограмму применяемый применяемый применяемый применяемый применяемый применяемый применяемый применяемый применяемый применяемый применяемый применяемый применяемый конструкторами конструкторами конструкторами конструкторами конструкторами конструкторами\n",
      "волосков up up up up up up up up up up up шукран шукран шукран шукран jove jove jove jove\n",
      "1 [D loss: 0.664056, acc.: 64.84%] [G loss: 0.690072]\n",
      "одиночном электроэнцефалограмму происходящем пулеметная пулеметная пулеметная пулеметная пулеметная пулеметная пулеметная пулеметная пулеметная пулеметная пулеметная пулеметная пулеметная пулеметная пулеметная пулеметная пулеметная\n",
      "lxd ртов ртов ртов ртов ртов ртов ртов ртов ртов ртов конструкторами конструкторами конструкторами конструкторами конструкторами конструкторами конструкторами конструкторами конструкторами\n",
      "волосков волосков волосков применяемый применяемый применяемый применяемый применяемый применяемый применяемый применяемый применяемый применяемый применяемый применяемый применяемый применяемый применяемый применяемый применяемый\n",
      "2 [D loss: 0.636497, acc.: 82.03%] [G loss: 0.737451]\n",
      "переходе переходе применяемый применяемый применяемый применяемый применяемый применяемый применяемый применяемый применяемый применяемый применяемый применяемый применяемый мудрых мудрых мудрых конструкторами конструкторами\n",
      "волосков применяемый применяемый применяемый применяемый применяемый применяемый применяемый применяемый применяемый применяемый применяемый применяемый применяемый применяемый применяемый нынешнее нынешнее нынешнее нынешнее\n",
      "волосков волосков волосков волосков гейтсом отступления отступления отступления отступления отступления отступления отступления отступления отступления отступления отступления отступления уходим уходим проведя\n",
      "3 [D loss: 0.615238, acc.: 90.62%] [G loss: 0.776701]\n",
      "электроэнцефалограмму электроэнцефалограмму происходящем происходящем шукран шукран шукран шукран шукран шукран шукран мудрых мудрых мудрых мудрых мудрых jove jove jove jove\n",
      "переходе переходе переходе спонтанный спонтанный спонтанный спонтанный спонтанный спонтанный спонтанный спонтанный спонтанный спонтанный спонтанный спонтанный нынешнее нынешнее нынешнее нынешнее нынешнее\n",
      "глазное 40. 40. 40. 40. 40. 40. 40. 40. 40. 40. 40. 40. 40. 40. jove jove jove jove jove\n",
      "4 [D loss: 0.589571, acc.: 100.00%] [G loss: 0.820586]\n",
      "волосков волосков волосков волосков мудрых мудрых мудрых мудрых мудрых мудрых мудрых мудрых мудрых мудрых мудрых мудрых мудрых мудрых мудрых нынешнее\n",
      "ручка электроэнцефалограмму ртов применяемый применяемый шукран шукран шукран шукран шукран шукран шукран шукран шукран шукран нынешнее нынешнее нынешнее нынешнее конструкторами\n",
      "волосков волосков применяемый применяемый пулеметная пулеметная пулеметная пулеметная пулеметная пулеметная пулеметная пулеметная пулеметная пулеметная пулеметная пулеметная пулеметная нынешнее нынешнее нынешнее\n"
     ]
    }
   ],
   "source": [
    "# Suppress warnings because the warning Keras gives us about non-trainable parameters is by design:\n",
    "# The Generator trainable parameters are intentionally held constant during Discriminator training and vice versa\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "\n",
    "iterations = 5\n",
    "batch_size = 64\n",
    "sample_interval = 1\n",
    "\n",
    "# Train the GAN for the specified number of iterations\n",
    "train(index2vectors(Xtrain), iterations, batch_size, sample_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
